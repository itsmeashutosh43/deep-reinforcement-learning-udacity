{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "#env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.14499999675899744\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(agent ,n_episodes=5000, max_t=2000):\n",
    "    all_scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        agent.reset()\n",
    "        env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "        states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "        while True:\n",
    "            actions = agent.act(states) # select an action (for each agent)\n",
    "            actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "            env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            agent.step(states,actions,rewards,next_states,dones)\n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            if np.any(dones):                                  # exit loop if episode finished\n",
    "                break\n",
    "        \n",
    "        print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))        \n",
    "        avg_score = np.mean(scores)\n",
    "        scores_window.append(avg_score)\n",
    "        all_scores.append(avg_score)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=30.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break \n",
    "            \n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom ddpg.ddpg_agent import *\\nconfig = Config(state_size,action_size,2,num_agents)    \\nagent = DDPG(config)\\nscores = ddpg(agent, n_episodes = 2000)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to run DDPG\n",
    "'''\n",
    "from ddpg.ddpg_agent import *\n",
    "config = Config(state_size,action_size,2,num_agents)    \n",
    "agent = DDPG(config)\n",
    "scores = ddpg(agent, n_episodes = 2000)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppo.actor_critic import *\n",
    "from ppo.agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.distributions import MultivariateNormal\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self,state_size,action_size):\n",
    "        super(ActorCritic,self).__init__()\n",
    "\n",
    "        \n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(state_size,256),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(128,action_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_size,256),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "        \n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.std = nn.Parameter(torch.zeros(action_size))\n",
    "\n",
    "        self.actor = self.actor.to(device)\n",
    "        self.critic = self.critic.to(device)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def act(self,states,memory,t):\n",
    "                \n",
    "        action_mean = self.actor(states)\n",
    "            \n",
    "        dist = torch.distributions.Normal(action_mean, F.softplus(self.std.to(device)))\n",
    "        actions = dist.sample() # --> 20 ,4\n",
    "        log_prob = dist.log_prob(actions).sum(dim = -1).unsqueeze(-1) #--> 20, 1\n",
    "        log_prob = torch.sum(log_prob, dim=-1) # --> 20,1\n",
    "        \n",
    "        for idx,(state,action,l_prob) in enumerate(zip(states,actions,log_prob)):\n",
    "            memory.states[t,idx,:] = state.cpu().data.numpy() # [33]\n",
    "            memory.actions[t,idx,:] = action.cpu().data.numpy()# [4] \n",
    "            memory.logprobs[t,idx] = l_prob.cpu().data.numpy()# [1]\n",
    "        \n",
    "        return actions.detach()\n",
    "\n",
    "    def evaluate(self, state ,action):\n",
    "        \n",
    "        action_mean = self.actor(state)\n",
    "        dist = torch.distributions.Normal(action_mean, F.softplus(self.std.to(device)))\n",
    "        log_prob = dist.log_prob(action).sum(dim = -1) # [1]\n",
    "        entropy = dist.entropy().sum(-1) # [1]\n",
    "        return log_prob, self.critic(state).squeeze(-1), entropy\n",
    "    \n",
    "    def find_state_value(self,state):\n",
    "        return self.critic(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sample(indices, batch_size):\n",
    "    indices = np.asarray(np.random.permutation(indices))\n",
    "    batches = indices[:len(indices) // batch_size * batch_size].reshape(-1, batch_size)\n",
    "    for batch in batches:\n",
    "        yield batch\n",
    "    r = len(indices) % batch_size\n",
    "    if r:\n",
    "        yield indices[-r:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import random\n",
    " \n",
    "\n",
    "SGD_EPOCH = 10              \n",
    "GAMMA = 0.99 \n",
    "gradient_clip= 5\n",
    "BETAS = (0,0)\n",
    "LR = 3e-4        \n",
    "BATCH_SIZE = 128\n",
    "\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.initialize_zeros()\n",
    "        \n",
    "    def initialize_zeros(self,MAX_T = 1000 ,num_agent = 20 , action_size = 4, state_size = 33):\n",
    "        self.actions = np.zeros((MAX_T, num_agent ,action_size))\n",
    "        self.states = np.zeros((MAX_T, num_agent ,state_size))\n",
    "        self.logprobs = np.zeros((MAX_T, num_agent))\n",
    "        self.rewards = np.zeros((MAX_T, num_agent))\n",
    "        self.is_terminals = np.zeros((MAX_T, num_agent))\n",
    "    def clear_memory(self):\n",
    "        \n",
    "        self.initialize_zeros()\n",
    "        \n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, state_size , action_size):\n",
    "        self.policy = ActorCritic(state_size, action_size)\n",
    "        self.optimizer = torch.optim.Adam(self.policy.parameters(), lr = LR, betas = BETAS)\n",
    "        self.policy_old = ActorCritic(state_size, action_size)\n",
    "        \n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        self.memory = Memory()\n",
    "        self.step_t = 0\n",
    "\n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def act(self, state, t):\n",
    "        state = torch.FloatTensor(state.reshape(20,-1)).to(device)\n",
    "        return self.policy_old.act(state,self.memory,t).cpu().data.numpy().flatten()\n",
    "\n",
    "\n",
    "    def collect_trajectories(self,rewards,dones,t):\n",
    "        \n",
    "        '''\n",
    "        After each step we will have, for each agent\n",
    "        state : [33]\n",
    "        action : [4]\n",
    "        l_prob : [1]\n",
    "        reward : [1]\n",
    "        is_terminal : [1]\n",
    "        \n",
    "        for 20 agents,\n",
    "        state : [20,33]\n",
    "        action : [20,4]\n",
    "        l_prob : [20,1]\n",
    "        reward : [20,1]\n",
    "        is_terminal : [20,1]\n",
    "        \n",
    "        --> next find_advantage. \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        count = 0\n",
    "        for idx ,(reward,done) in enumerate(zip(rewards,dones)):\n",
    "            self.memory.rewards[t,idx] = reward#[1]\n",
    "            self.memory.is_terminals[t,idx] = done #[1]\n",
    "              \n",
    "        \n",
    "        \n",
    "    def find_advantage(self,states,rewards,dones):\n",
    "        \n",
    "        '''\n",
    "        Find advantage for each state,action,reward tuple\n",
    "        \n",
    "        The entire memory for a horizon of length T will be:\n",
    "        \n",
    "        state : [T,20,33]\n",
    "        action : [T,20,4]\n",
    "        l_prob : [T,20,1]\n",
    "        reward : [T,20,1]\n",
    "        is_terminal : [T,20,1]\n",
    "        '''\n",
    "        \n",
    "        T = states.size(0)\n",
    "        advantages = np.zeros((T,20))\n",
    "        returns = np.zeros((T,20))\n",
    "\n",
    "        \n",
    "        for idx in range(20):\n",
    "            ret = self.policy_old.find_state_value(states[T-1,idx,:]).squeeze(-1).detach()\n",
    "            returns[T-1,idx] = ret\n",
    "            for i in reversed(range(T-1)):\n",
    "                ret = rewards[i,idx] + GAMMA * (1 - dones[i,idx]) * ret\n",
    "                state = states[i,idx,:] # T,33\n",
    "                state_value = self.policy_old.find_state_value(state).squeeze(-1).detach() # T,\n",
    "                advantages[i,idx] = ret - state_value\n",
    "                returns[i,idx] = ret\n",
    "                \n",
    "        return torch.from_numpy(advantages).to(device),torch.from_numpy(returns).to(device)\n",
    "            \n",
    "\n",
    "    def step(self,epsilon,beta):\n",
    "        self.learn(epsilon ,beta)\n",
    "        self.memory.clear_memory()\n",
    "        \n",
    "\n",
    "    def learn(self, epsilon, beta):\n",
    "        \n",
    "        states = torch.from_numpy(self.memory.states).float().to(device).detach()\n",
    "        actions = torch.from_numpy(self.memory.actions).float().to(device).detach()\n",
    "        rewards = torch.from_numpy(self.memory.rewards).float().to(device).detach()    \n",
    "        is_terminals = torch.from_numpy(self.memory.is_terminals.astype(np.uint8)).float().to(device).detach()\n",
    "        old_probs = torch.from_numpy(self.memory.logprobs).float().to(device).detach()            \n",
    "            \n",
    "        advantages,returns = self.find_advantage(states,rewards,is_terminals)\n",
    "        \n",
    "        advantages = (advantages - advantages.mean())/advantages.std()\n",
    "            \n",
    "            \n",
    "        \n",
    "        for _ in range(SGD_EPOCH):\n",
    "            sampler = random_sample(np.arange(states.size(0)), BATCH_SIZE)\n",
    "            for batch_indices in sampler:\n",
    "                batch_indices = torch.tensor(batch_indices).long()\n",
    "                sampled_states = states[batch_indices] # BATCH * 33\n",
    "                sampled_actions = actions[batch_indices] # BATCH * 4\n",
    "                sampled_log_probs_old = old_probs[batch_indices] # BATCH,\n",
    "                sampled_advantages = advantages[batch_indices] # BATCH,\n",
    "                sampled_returns = returns[batch_indices]\n",
    "                \n",
    "                logprobs, state_values, dist_entropy = self.policy.evaluate(sampled_states,sampled_actions)\n",
    "                \n",
    "                ratios = torch.exp(logprobs - sampled_log_probs_old)\n",
    "                \n",
    "            \n",
    "                surr1 = sampled_advantages * ratios\n",
    "                surr2 = torch.clamp(ratios,1 - epsilon , 1+ epsilon) * sampled_advantages \n",
    "                                \n",
    "                loss1 =  torch.min(surr1,surr2)\n",
    "                loss2 = self.MseLoss(sampled_returns , state_values)\n",
    "                loss3 = beta * dist_entropy\n",
    "            \n",
    "                \n",
    "                loss = - loss1.mean() + loss2 - loss3.mean()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = PPO(state_size,action_size)\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo(agent ,n_episodes=5000, max_t=1000):\n",
    "    all_scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    \n",
    "    eps_clip = 0.1\n",
    "    beta = 0.01\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        \n",
    "        env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "        state = env_info.vector_observations                  # get the current state (for each agent)\n",
    "        scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "        for p in range(max_t):\n",
    "            action = agent.act(state,p) # select an action (for each agent)\n",
    "            env_info = env.step(action)[brain_name]           # send all actions to tne environment\n",
    "            next_state = env_info.vector_observations         # get next state (for each agent)\n",
    "            reward = env_info.rewards                      # get reward (for each agent)\n",
    "            done = env_info.local_done                        # see if episode finished\n",
    "            agent.collect_trajectories(reward,done,p)\n",
    "            scores += env_info.rewards                         # update the score (for each agent)\n",
    "            state = next_state                               # roll over states to next time step\n",
    "            if np.any(done):                                  # exit loop if episode finished\n",
    "                break\n",
    "             \n",
    "        \n",
    "        agent.step(eps_clip,beta)\n",
    "        \n",
    "        print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))        \n",
    "        avg_score = np.mean(scores)\n",
    "        scores_window.append(avg_score)\n",
    "        all_scores.append(avg_score)\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=30.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            \n",
    "            torch.save(agent.policy.state_dict(), 'checkpoint_ppo_30.pth')\n",
    "            break \n",
    "            \n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.5279999881982803\n",
      "Episode 1\tAverage Score: 0.53Total score (averaged over agents) this episode: 0.5429999878630042\n",
      "Episode 2\tAverage Score: 0.54Total score (averaged over agents) this episode: 0.7179999839514494\n",
      "Episode 3\tAverage Score: 0.60Total score (averaged over agents) this episode: 0.7659999828785657\n",
      "Episode 4\tAverage Score: 0.64Total score (averaged over agents) this episode: 0.518999988399446\n",
      "Episode 5\tAverage Score: 0.61Total score (averaged over agents) this episode: 0.43199999034404757\n",
      "Episode 6\tAverage Score: 0.58Total score (averaged over agents) this episode: 0.6134999862872064\n",
      "Episode 7\tAverage Score: 0.59Total score (averaged over agents) this episode: 0.8424999811686575\n",
      "Episode 8\tAverage Score: 0.62Total score (averaged over agents) this episode: 0.6139999862760306\n",
      "Episode 9\tAverage Score: 0.62Total score (averaged over agents) this episode: 0.7984999821521341\n",
      "Episode 10\tAverage Score: 0.64Total score (averaged over agents) this episode: 0.8109999818727374\n",
      "Episode 11\tAverage Score: 0.65Total score (averaged over agents) this episode: 0.7334999836049974\n",
      "Episode 12\tAverage Score: 0.66Total score (averaged over agents) this episode: 0.6604999852366745\n",
      "Episode 13\tAverage Score: 0.66Total score (averaged over agents) this episode: 0.8989999799057842\n",
      "Episode 14\tAverage Score: 0.68Total score (averaged over agents) this episode: 0.7909999823197722\n",
      "Episode 15\tAverage Score: 0.68Total score (averaged over agents) this episode: 1.0634999762289226\n",
      "Episode 16\tAverage Score: 0.71Total score (averaged over agents) this episode: 1.2989999709650875\n",
      "Episode 17\tAverage Score: 0.74Total score (averaged over agents) this episode: 1.0254999770782889\n",
      "Episode 18\tAverage Score: 0.76Total score (averaged over agents) this episode: 1.180999973602593\n",
      "Episode 19\tAverage Score: 0.78Total score (averaged over agents) this episode: 1.017999977245927\n",
      "Episode 20\tAverage Score: 0.79Total score (averaged over agents) this episode: 1.447999967634678\n",
      "Episode 21\tAverage Score: 0.82Total score (averaged over agents) this episode: 1.246499972138554\n",
      "Episode 22\tAverage Score: 0.84Total score (averaged over agents) this episode: 1.2499999720603228\n",
      "Episode 23\tAverage Score: 0.86Total score (averaged over agents) this episode: 1.4244999681599437\n",
      "Episode 24\tAverage Score: 0.88Total score (averaged over agents) this episode: 1.5409999655559659\n",
      "Episode 25\tAverage Score: 0.91Total score (averaged over agents) this episode: 1.2614999718032778\n",
      "Episode 26\tAverage Score: 0.92Total score (averaged over agents) this episode: 1.3504999698139728\n",
      "Episode 27\tAverage Score: 0.94Total score (averaged over agents) this episode: 1.4564999674446881\n",
      "Episode 28\tAverage Score: 0.96Total score (averaged over agents) this episode: 1.3934999688528478\n",
      "Episode 29\tAverage Score: 0.97Total score (averaged over agents) this episode: 1.38649996900931\n",
      "Episode 30\tAverage Score: 0.99Total score (averaged over agents) this episode: 1.8409999588504433\n",
      "Episode 31\tAverage Score: 1.01Total score (averaged over agents) this episode: 1.4489999676123262\n",
      "Episode 32\tAverage Score: 1.03Total score (averaged over agents) this episode: 1.668999962694943\n",
      "Episode 33\tAverage Score: 1.05Total score (averaged over agents) this episode: 1.619499963801354\n",
      "Episode 34\tAverage Score: 1.06Total score (averaged over agents) this episode: 1.5899999644607306\n",
      "Episode 35\tAverage Score: 1.08Total score (averaged over agents) this episode: 1.913499957229942\n",
      "Episode 36\tAverage Score: 1.10Total score (averaged over agents) this episode: 2.2614999494515358\n",
      "Episode 37\tAverage Score: 1.13Total score (averaged over agents) this episode: 1.661499962862581\n",
      "Episode 38\tAverage Score: 1.15Total score (averaged over agents) this episode: 2.160999951697886\n",
      "Episode 39\tAverage Score: 1.17Total score (averaged over agents) this episode: 1.8749999580904841\n",
      "Episode 40\tAverage Score: 1.19Total score (averaged over agents) this episode: 1.9879999555647374\n",
      "Episode 41\tAverage Score: 1.21Total score (averaged over agents) this episode: 1.9584999562241137\n",
      "Episode 42\tAverage Score: 1.23Total score (averaged over agents) this episode: 2.3029999485239387\n",
      "Episode 43\tAverage Score: 1.25Total score (averaged over agents) this episode: 1.9509999563917517\n",
      "Episode 44\tAverage Score: 1.27Total score (averaged over agents) this episode: 2.1714999514631925\n",
      "Episode 45\tAverage Score: 1.29Total score (averaged over agents) this episode: 2.1284999524243178\n",
      "Episode 46\tAverage Score: 1.31Total score (averaged over agents) this episode: 2.3524999474175274\n",
      "Episode 47\tAverage Score: 1.33Total score (averaged over agents) this episode: 2.6384999410249295\n",
      "Episode 48\tAverage Score: 1.36Total score (averaged over agents) this episode: 2.216499950457364\n",
      "Episode 49\tAverage Score: 1.37Total score (averaged over agents) this episode: 2.652499940712005\n",
      "Episode 50\tAverage Score: 1.40Total score (averaged over agents) this episode: 2.3094999483786522\n",
      "Episode 51\tAverage Score: 1.42Total score (averaged over agents) this episode: 2.8209999369457366\n",
      "Episode 52\tAverage Score: 1.45Total score (averaged over agents) this episode: 2.5089999439194797\n",
      "Episode 53\tAverage Score: 1.47Total score (averaged over agents) this episode: 2.9464999341405926\n",
      "Episode 54\tAverage Score: 1.49Total score (averaged over agents) this episode: 2.275999949127436\n",
      "Episode 55\tAverage Score: 1.51Total score (averaged over agents) this episode: 2.2024999507702887\n",
      "Episode 56\tAverage Score: 1.52Total score (averaged over agents) this episode: 3.1684999291785063\n",
      "Episode 57\tAverage Score: 1.55Total score (averaged over agents) this episode: 2.772499938029796\n",
      "Episode 58\tAverage Score: 1.57Total score (averaged over agents) this episode: 3.233499927725643\n",
      "Episode 59\tAverage Score: 1.60Total score (averaged over agents) this episode: 3.094999930821359\n",
      "Episode 60\tAverage Score: 1.62Total score (averaged over agents) this episode: 3.1959999285638334\n",
      "Episode 61\tAverage Score: 1.65Total score (averaged over agents) this episode: 3.1244999301619827\n",
      "Episode 62\tAverage Score: 1.67Total score (averaged over agents) this episode: 3.2714999268762766\n",
      "Episode 63\tAverage Score: 1.70Total score (averaged over agents) this episode: 2.9019999351352452\n",
      "Episode 64\tAverage Score: 1.72Total score (averaged over agents) this episode: 2.9844999332912265\n",
      "Episode 65\tAverage Score: 1.74Total score (averaged over agents) this episode: 2.9609999338164927\n",
      "Episode 66\tAverage Score: 1.75Total score (averaged over agents) this episode: 3.3339999254792927\n",
      "Episode 67\tAverage Score: 1.78Total score (averaged over agents) this episode: 3.756499916035682\n",
      "Episode 68\tAverage Score: 1.81Total score (averaged over agents) this episode: 3.4489999229088424\n",
      "Episode 69\tAverage Score: 1.83Total score (averaged over agents) this episode: 3.7729999156668783\n",
      "Episode 70\tAverage Score: 1.86Total score (averaged over agents) this episode: 3.4279999233782292\n",
      "Episode 71\tAverage Score: 1.88Total score (averaged over agents) this episode: 3.6309999188408257\n",
      "Episode 72\tAverage Score: 1.91Total score (averaged over agents) this episode: 3.8014999150298534\n",
      "Episode 73\tAverage Score: 1.93Total score (averaged over agents) this episode: 3.5224999212659895\n",
      "Episode 74\tAverage Score: 1.95Total score (averaged over agents) this episode: 3.89549991292879\n",
      "Episode 75\tAverage Score: 1.98Total score (averaged over agents) this episode: 4.118999907933175\n",
      "Episode 76\tAverage Score: 2.01Total score (averaged over agents) this episode: 4.8089998925104736\n",
      "Episode 77\tAverage Score: 2.04Total score (averaged over agents) this episode: 4.379499902110547\n",
      "Episode 78\tAverage Score: 2.07Total score (averaged over agents) this episode: 5.162499884609133\n",
      "Episode 79\tAverage Score: 2.11Total score (averaged over agents) this episode: 4.688499895203859\n",
      "Episode 80\tAverage Score: 2.14Total score (averaged over agents) this episode: 4.549499898310751\n",
      "Episode 81\tAverage Score: 2.17Total score (averaged over agents) this episode: 4.210499905887991\n",
      "Episode 82\tAverage Score: 2.20Total score (averaged over agents) this episode: 4.438499900791794\n",
      "Episode 83\tAverage Score: 2.23Total score (averaged over agents) this episode: 4.6934998950921\n",
      "Episode 84\tAverage Score: 2.26Total score (averaged over agents) this episode: 5.22749988315627\n",
      "Episode 85\tAverage Score: 2.29Total score (averaged over agents) this episode: 4.777499893214554\n",
      "Episode 86\tAverage Score: 2.32Total score (averaged over agents) this episode: 4.171499906759709\n",
      "Episode 87\tAverage Score: 2.34Total score (averaged over agents) this episode: 5.315499881189316\n",
      "Episode 88\tAverage Score: 2.37Total score (averaged over agents) this episode: 4.61599989682436\n",
      "Episode 89\tAverage Score: 2.40Total score (averaged over agents) this episode: 4.985499888565391\n",
      "Episode 90\tAverage Score: 2.43Total score (averaged over agents) this episode: 5.657499873545021\n",
      "Episode 91\tAverage Score: 2.46Total score (averaged over agents) this episode: 4.921499889995903\n",
      "Episode 92\tAverage Score: 2.49Total score (averaged over agents) this episode: 4.450499900523573\n",
      "Episode 93\tAverage Score: 2.51Total score (averaged over agents) this episode: 5.848999869264662\n",
      "Episode 94\tAverage Score: 2.55Total score (averaged over agents) this episode: 5.431999878585339\n",
      "Episode 95\tAverage Score: 2.58Total score (averaged over agents) this episode: 5.132499885279685\n",
      "Episode 96\tAverage Score: 2.60Total score (averaged over agents) this episode: 4.974999888800085\n",
      "Episode 97\tAverage Score: 2.63Total score (averaged over agents) this episode: 5.923499867599458\n",
      "Episode 98\tAverage Score: 2.66Total score (averaged over agents) this episode: 4.903499890398234\n",
      "Episode 99\tAverage Score: 2.68Total score (averaged over agents) this episode: 5.26149988239631\n",
      "Episode 100\tAverage Score: 2.71\n",
      "Total score (averaged over agents) this episode: 5.109499885793776\n",
      "Episode 101\tAverage Score: 2.76Total score (averaged over agents) this episode: 4.780499893147498\n",
      "Episode 102\tAverage Score: 2.80Total score (averaged over agents) this episode: 4.856499891448766\n",
      "Episode 103\tAverage Score: 2.84Total score (averaged over agents) this episode: 4.472499900031835\n",
      "Episode 104\tAverage Score: 2.88Total score (averaged over agents) this episode: 5.4684998777695\n",
      "Episode 105\tAverage Score: 2.93Total score (averaged over agents) this episode: 4.554499898198992\n",
      "Episode 106\tAverage Score: 2.97Total score (averaged over agents) this episode: 4.757499893661588\n",
      "Episode 107\tAverage Score: 3.01Total score (averaged over agents) this episode: 4.017499910201877\n",
      "Episode 108\tAverage Score: 3.04Total score (averaged over agents) this episode: 3.830499914381653\n",
      "Episode 109\tAverage Score: 3.07Total score (averaged over agents) this episode: 4.433999900892377\n",
      "Episode 110\tAverage Score: 3.11Total score (averaged over agents) this episode: 4.969999888911843\n",
      "Episode 111\tAverage Score: 3.15Total score (averaged over agents) this episode: 4.328499903250486\n",
      "Episode 112\tAverage Score: 3.19Total score (averaged over agents) this episode: 5.37649987982586\n",
      "Episode 113\tAverage Score: 3.23Total score (averaged over agents) this episode: 3.8914999130181966\n",
      "Episode 114\tAverage Score: 3.26Total score (averaged over agents) this episode: 4.34349990291521\n",
      "Episode 115\tAverage Score: 3.30Total score (averaged over agents) this episode: 4.537499898578972\n",
      "Episode 116\tAverage Score: 3.33Total score (averaged over agents) this episode: 4.127499907743186\n",
      "Episode 117\tAverage Score: 3.36Total score (averaged over agents) this episode: 4.538999898545444\n",
      "Episode 118\tAverage Score: 3.40Total score (averaged over agents) this episode: 4.0504999094642695\n",
      "Episode 119\tAverage Score: 3.43Total score (averaged over agents) this episode: 5.80999987013638\n",
      "Episode 120\tAverage Score: 3.47Total score (averaged over agents) this episode: 6.273999859765172\n",
      "Episode 121\tAverage Score: 3.52Total score (averaged over agents) this episode: 5.372499879915267\n",
      "Episode 122\tAverage Score: 3.56Total score (averaged over agents) this episode: 5.8414998694323\n",
      "Episode 123\tAverage Score: 3.61Total score (averaged over agents) this episode: 5.3959998793900015\n",
      "Episode 124\tAverage Score: 3.65Total score (averaged over agents) this episode: 5.363999880105257\n",
      "Episode 125\tAverage Score: 3.69Total score (averaged over agents) this episode: 5.354999880306423\n",
      "Episode 126\tAverage Score: 3.73Total score (averaged over agents) this episode: 5.953499866928905\n",
      "Episode 127\tAverage Score: 3.77Total score (averaged over agents) this episode: 5.196499883849174\n",
      "Episode 128\tAverage Score: 3.81Total score (averaged over agents) this episode: 6.0859998639673\n",
      "Episode 129\tAverage Score: 3.86Total score (averaged over agents) this episode: 5.88749986840412\n",
      "Episode 130\tAverage Score: 3.90Total score (averaged over agents) this episode: 6.176999861933291\n",
      "Episode 131\tAverage Score: 3.95Total score (averaged over agents) this episode: 5.762999871186912\n",
      "Episode 132\tAverage Score: 3.99Total score (averaged over agents) this episode: 6.233499860670418\n",
      "Episode 133\tAverage Score: 4.04Total score (averaged over agents) this episode: 6.321999858692289\n",
      "Episode 134\tAverage Score: 4.08Total score (averaged over agents) this episode: 7.205499838944524\n",
      "Episode 135\tAverage Score: 4.14Total score (averaged over agents) this episode: 6.158499862346798\n",
      "Episode 136\tAverage Score: 4.18Total score (averaged over agents) this episode: 6.510499854478985\n",
      "Episode 137\tAverage Score: 4.22Total score (averaged over agents) this episode: 6.216999861039222\n",
      "Episode 138\tAverage Score: 4.27Total score (averaged over agents) this episode: 5.915999867767096\n",
      "Episode 139\tAverage Score: 4.31Total score (averaged over agents) this episode: 7.102499841246754\n",
      "Episode 140\tAverage Score: 4.36Total score (averaged over agents) this episode: 5.9054998680017885\n",
      "Episode 141\tAverage Score: 4.40Total score (averaged over agents) this episode: 6.436499856133014\n",
      "Episode 142\tAverage Score: 4.44Total score (averaged over agents) this episode: 6.893499845918268\n",
      "Episode 143\tAverage Score: 4.49Total score (averaged over agents) this episode: 7.186999839358032\n",
      "Episode 144\tAverage Score: 4.54Total score (averaged over agents) this episode: 8.556499808747322\n",
      "Episode 145\tAverage Score: 4.61Total score (averaged over agents) this episode: 8.157499817665666\n",
      "Episode 146\tAverage Score: 4.67Total score (averaged over agents) this episode: 6.3649998577311635\n",
      "Episode 147\tAverage Score: 4.71Total score (averaged over agents) this episode: 6.332499858457595\n",
      "Episode 148\tAverage Score: 4.74Total score (averaged over agents) this episode: 6.920499845314771\n",
      "Episode 149\tAverage Score: 4.79Total score (averaged over agents) this episode: 7.6069998299703006\n",
      "Episode 150\tAverage Score: 4.84Total score (averaged over agents) this episode: 7.510999832116068\n",
      "Episode 151\tAverage Score: 4.89Total score (averaged over agents) this episode: 7.126999840699137\n",
      "Episode 152\tAverage Score: 4.93Total score (averaged over agents) this episode: 7.78499982599169\n",
      "Episode 153\tAverage Score: 4.99Total score (averaged over agents) this episode: 8.067999819666147\n",
      "Episode 154\tAverage Score: 5.04Total score (averaged over agents) this episode: 7.779499826114625\n",
      "Episode 155\tAverage Score: 5.09Total score (averaged over agents) this episode: 8.242999815754592\n",
      "Episode 156\tAverage Score: 5.15Total score (averaged over agents) this episode: 8.819999802857637\n",
      "Episode 157\tAverage Score: 5.21Total score (averaged over agents) this episode: 9.325499791558832\n",
      "Episode 158\tAverage Score: 5.28Total score (averaged over agents) this episode: 8.48249981040135\n",
      "Episode 159\tAverage Score: 5.33Total score (averaged over agents) this episode: 9.027999798208475\n",
      "Episode 160\tAverage Score: 5.39Total score (averaged over agents) this episode: 8.988499799091368\n",
      "Episode 161\tAverage Score: 5.45Total score (averaged over agents) this episode: 7.594499830249697\n",
      "Episode 162\tAverage Score: 5.49Total score (averaged over agents) this episode: 9.057999797537923\n",
      "Episode 163\tAverage Score: 5.55Total score (averaged over agents) this episode: 8.617999807372689\n",
      "Episode 164\tAverage Score: 5.61Total score (averaged over agents) this episode: 10.538499764446168\n",
      "Episode 165\tAverage Score: 5.68Total score (averaged over agents) this episode: 7.959999822080135\n",
      "Episode 166\tAverage Score: 5.73Total score (averaged over agents) this episode: 9.727499782573432\n",
      "Episode 167\tAverage Score: 5.80Total score (averaged over agents) this episode: 10.848999757505954\n",
      "Episode 168\tAverage Score: 5.87Total score (averaged over agents) this episode: 9.258499793056398\n",
      "Episode 169\tAverage Score: 5.92Total score (averaged over agents) this episode: 9.69349978333339\n",
      "Episode 170\tAverage Score: 5.98Total score (averaged over agents) this episode: 10.562499763909727\n",
      "Episode 171\tAverage Score: 6.05Total score (averaged over agents) this episode: 10.81849975818768\n",
      "Episode 172\tAverage Score: 6.13Total score (averaged over agents) this episode: 11.9564997327514\n",
      "Episode 173\tAverage Score: 6.21Total score (averaged over agents) this episode: 10.447499766480178\n",
      "Episode 174\tAverage Score: 6.28Total score (averaged over agents) this episode: 12.167999728024006\n",
      "Episode 175\tAverage Score: 6.36Total score (averaged over agents) this episode: 12.539499719720334\n",
      "Episode 176\tAverage Score: 6.44Total score (averaged over agents) this episode: 11.552999741770327\n",
      "Episode 177\tAverage Score: 6.51Total score (averaged over agents) this episode: 11.14299975093454\n",
      "Episode 178\tAverage Score: 6.58Total score (averaged over agents) this episode: 13.71249969350174\n",
      "Episode 179\tAverage Score: 6.66Total score (averaged over agents) this episode: 10.964999754913151\n",
      "Episode 180\tAverage Score: 6.73Total score (averaged over agents) this episode: 12.844499712903053\n",
      "Episode 181\tAverage Score: 6.81Total score (averaged over agents) this episode: 12.77999971434474\n",
      "Episode 182\tAverage Score: 6.90Total score (averaged over agents) this episode: 12.109499729331583\n",
      "Episode 183\tAverage Score: 6.97Total score (averaged over agents) this episode: 12.332999724335968\n",
      "Episode 184\tAverage Score: 7.05Total score (averaged over agents) this episode: 10.849999757483602\n",
      "Episode 185\tAverage Score: 7.11Total score (averaged over agents) this episode: 13.642499695066363\n",
      "Episode 186\tAverage Score: 7.19Total score (averaged over agents) this episode: 12.946499710623176\n",
      "Episode 187\tAverage Score: 7.28Total score (averaged over agents) this episode: 12.475499721150845\n",
      "Episode 188\tAverage Score: 7.35Total score (averaged over agents) this episode: 14.162499683443457\n",
      "Episode 189\tAverage Score: 7.45Total score (averaged over agents) this episode: 12.970999710075557\n",
      "Episode 190\tAverage Score: 7.53Total score (averaged over agents) this episode: 11.938999733142555\n",
      "Episode 191\tAverage Score: 7.59Total score (averaged over agents) this episode: 12.03299973104149\n",
      "Episode 192\tAverage Score: 7.66Total score (averaged over agents) this episode: 13.381499700900168\n",
      "Episode 193\tAverage Score: 7.75Total score (averaged over agents) this episode: 14.751999670267105\n",
      "Episode 194\tAverage Score: 7.84Total score (averaged over agents) this episode: 14.74049967052415\n",
      "Episode 195\tAverage Score: 7.93Total score (averaged over agents) this episode: 15.79999964684248\n",
      "Episode 196\tAverage Score: 8.04Total score (averaged over agents) this episode: 14.387999678403139\n",
      "Episode 197\tAverage Score: 8.14Total score (averaged over agents) this episode: 13.727999693155288\n",
      "Episode 198\tAverage Score: 8.21Total score (averaged over agents) this episode: 13.710999693535268\n",
      "Episode 199\tAverage Score: 8.30Total score (averaged over agents) this episode: 14.167499683331698\n",
      "Episode 200\tAverage Score: 8.39\n",
      "Total score (averaged over agents) this episode: 13.798999691568316\n",
      "Episode 201\tAverage Score: 8.48Total score (averaged over agents) this episode: 14.669499672111124\n",
      "Episode 202\tAverage Score: 8.58Total score (averaged over agents) this episode: 15.144499661494047\n",
      "Episode 203\tAverage Score: 8.68Total score (averaged over agents) this episode: 14.666999672167004\n",
      "Episode 204\tAverage Score: 8.78Total score (averaged over agents) this episode: 15.271499658655376\n",
      "Episode 205\tAverage Score: 8.88Total score (averaged over agents) this episode: 15.962499643210322\n",
      "Episode 206\tAverage Score: 8.99Total score (averaged over agents) this episode: 15.056999663449824\n",
      "Episode 207\tAverage Score: 9.10Total score (averaged over agents) this episode: 16.966499620769174\n",
      "Episode 208\tAverage Score: 9.23Total score (averaged over agents) this episode: 14.370999678783118\n",
      "Episode 209\tAverage Score: 9.33Total score (averaged over agents) this episode: 16.490499631408603\n",
      "Episode 210\tAverage Score: 9.45Total score (averaged over agents) this episode: 15.965499643143266\n",
      "Episode 211\tAverage Score: 9.56Total score (averaged over agents) this episode: 15.499999653548002\n",
      "Episode 212\tAverage Score: 9.67Total score (averaged over agents) this episode: 17.17549961609766\n",
      "Episode 213\tAverage Score: 9.79Total score (averaged over agents) this episode: 16.242499636951834\n",
      "Episode 214\tAverage Score: 9.91Total score (averaged over agents) this episode: 14.996999664790929\n",
      "Episode 215\tAverage Score: 10.02Total score (averaged over agents) this episode: 15.757999647781253\n",
      "Episode 216\tAverage Score: 10.13Total score (averaged over agents) this episode: 15.568999652005733\n",
      "Episode 217\tAverage Score: 10.25Total score (averaged over agents) this episode: 16.09549964023754\n",
      "Episode 218\tAverage Score: 10.36Total score (averaged over agents) this episode: 14.50799967572093\n",
      "Episode 219\tAverage Score: 10.47Total score (averaged over agents) this episode: 18.18699959348887\n",
      "Episode 220\tAverage Score: 10.59Total score (averaged over agents) this episode: 17.238999614678324\n",
      "Episode 221\tAverage Score: 10.70Total score (averaged over agents) this episode: 16.18399963825941\n",
      "Episode 222\tAverage Score: 10.81Total score (averaged over agents) this episode: 15.899999644607306\n",
      "Episode 223\tAverage Score: 10.91Total score (averaged over agents) this episode: 14.479499676357955\n",
      "Episode 224\tAverage Score: 11.00Total score (averaged over agents) this episode: 18.30199959091842\n",
      "Episode 225\tAverage Score: 11.13Total score (averaged over agents) this episode: 15.381499656196684\n",
      "Episode 226\tAverage Score: 11.23Total score (averaged over agents) this episode: 14.084999685175717\n",
      "Episode 227\tAverage Score: 11.31Total score (averaged over agents) this episode: 16.447999632358552\n",
      "Episode 228\tAverage Score: 11.42Total score (averaged over agents) this episode: 16.338499634806066\n",
      "Episode 229\tAverage Score: 11.53Total score (averaged over agents) this episode: 16.026999641768633\n",
      "Episode 230\tAverage Score: 11.63Total score (averaged over agents) this episode: 13.119999706745148\n",
      "Episode 231\tAverage Score: 11.70Total score (averaged over agents) this episode: 16.876999622769652\n",
      "Episode 232\tAverage Score: 11.81Total score (averaged over agents) this episode: 16.647999627888204\n",
      "Episode 233\tAverage Score: 11.91Total score (averaged over agents) this episode: 14.842999668233096\n",
      "Episode 234\tAverage Score: 12.00Total score (averaged over agents) this episode: 16.498499631229787\n",
      "Episode 235\tAverage Score: 12.09Total score (averaged over agents) this episode: 17.856999600864945\n",
      "Episode 236\tAverage Score: 12.21Total score (averaged over agents) this episode: 15.562999652139842\n",
      "Episode 237\tAverage Score: 12.30Total score (averaged over agents) this episode: 15.837999645993113\n",
      "Episode 238\tAverage Score: 12.39Total score (averaged over agents) this episode: 15.369499656464905\n",
      "Episode 239\tAverage Score: 12.49Total score (averaged over agents) this episode: 17.590499606821687\n",
      "Episode 240\tAverage Score: 12.59Total score (averaged over agents) this episode: 18.070999596081673\n",
      "Episode 241\tAverage Score: 12.72Total score (averaged over agents) this episode: 17.030499619338663\n",
      "Episode 242\tAverage Score: 12.82Total score (averaged over agents) this episode: 16.563499629776924\n",
      "Episode 243\tAverage Score: 12.92Total score (averaged over agents) this episode: 16.552499630022794\n",
      "Episode 244\tAverage Score: 13.01Total score (averaged over agents) this episode: 16.103499640058725\n",
      "Episode 245\tAverage Score: 13.09Total score (averaged over agents) this episode: 19.480499564576895\n",
      "Episode 246\tAverage Score: 13.20Total score (averaged over agents) this episode: 18.289499591197817\n",
      "Episode 247\tAverage Score: 13.32Total score (averaged over agents) this episode: 19.64799956083298\n",
      "Episode 248\tAverage Score: 13.45Total score (averaged over agents) this episode: 16.87149962289259\n",
      "Episode 249\tAverage Score: 13.55Total score (averaged over agents) this episode: 18.615499583911152\n",
      "Episode 250\tAverage Score: 13.66Total score (averaged over agents) this episode: 18.803499579709023\n",
      "Episode 251\tAverage Score: 13.78Total score (averaged over agents) this episode: 17.769499602820723\n",
      "Episode 252\tAverage Score: 13.88Total score (averaged over agents) this episode: 18.7159995816648\n",
      "Episode 253\tAverage Score: 13.99Total score (averaged over agents) this episode: 18.99799957536161\n",
      "Episode 254\tAverage Score: 14.10Total score (averaged over agents) this episode: 20.296499546337873\n",
      "Episode 255\tAverage Score: 14.23Total score (averaged over agents) this episode: 20.366999544762074\n",
      "Episode 256\tAverage Score: 14.35Total score (averaged over agents) this episode: 18.637499583419412\n",
      "Episode 257\tAverage Score: 14.45Total score (averaged over agents) this episode: 20.745999536290764\n",
      "Episode 258\tAverage Score: 14.56Total score (averaged over agents) this episode: 20.118499550316482\n",
      "Episode 259\tAverage Score: 14.68Total score (averaged over agents) this episode: 20.48749954206869\n",
      "Episode 260\tAverage Score: 14.79Total score (averaged over agents) this episode: 19.11649957271293\n",
      "Episode 261\tAverage Score: 14.89Total score (averaged over agents) this episode: 17.512999608553947\n",
      "Episode 262\tAverage Score: 14.99Total score (averaged over agents) this episode: 17.887999600172044\n",
      "Episode 263\tAverage Score: 15.08Total score (averaged over agents) this episode: 20.73799953646958\n",
      "Episode 264\tAverage Score: 15.20Total score (averaged over agents) this episode: 20.21499954815954\n",
      "Episode 265\tAverage Score: 15.30Total score (averaged over agents) this episode: 17.744999603368342\n",
      "Episode 266\tAverage Score: 15.40Total score (averaged over agents) this episode: 16.270499636325987\n",
      "Episode 267\tAverage Score: 15.46Total score (averaged over agents) this episode: 16.686999627016483\n",
      "Episode 268\tAverage Score: 15.52Total score (averaged over agents) this episode: 19.073499573674052\n",
      "Episode 269\tAverage Score: 15.62Total score (averaged over agents) this episode: 19.352499567437917\n",
      "Episode 270\tAverage Score: 15.71Total score (averaged over agents) this episode: 19.309999568387866\n",
      "Episode 271\tAverage Score: 15.80Total score (averaged over agents) this episode: 17.33199961259961\n",
      "Episode 272\tAverage Score: 15.87Total score (averaged over agents) this episode: 17.167499616276473\n",
      "Episode 273\tAverage Score: 15.92Total score (averaged over agents) this episode: 17.802499602083117\n",
      "Episode 274\tAverage Score: 15.99Total score (averaged over agents) this episode: 19.211999570578335\n",
      "Episode 275\tAverage Score: 16.06Total score (averaged over agents) this episode: 17.842999601177873\n",
      "Episode 276\tAverage Score: 16.12Total score (averaged over agents) this episode: 17.465999609604477\n",
      "Episode 277\tAverage Score: 16.17Total score (averaged over agents) this episode: 17.156999616511165\n",
      "Episode 278\tAverage Score: 16.23Total score (averaged over agents) this episode: 17.17449961612001\n",
      "Episode 279\tAverage Score: 16.27Total score (averaged over agents) this episode: 17.359499611984937\n",
      "Episode 280\tAverage Score: 16.33Total score (averaged over agents) this episode: 19.089499573316424\n",
      "Episode 281\tAverage Score: 16.40Total score (averaged over agents) this episode: 19.507499563973397\n",
      "Episode 282\tAverage Score: 16.46Total score (averaged over agents) this episode: 17.099999617785215\n",
      "Episode 283\tAverage Score: 16.51Total score (averaged over agents) this episode: 19.692499559838325\n",
      "Episode 284\tAverage Score: 16.59Total score (averaged over agents) this episode: 20.686499537620694\n",
      "Episode 285\tAverage Score: 16.68Total score (averaged over agents) this episode: 20.050999551825225\n",
      "Episode 286\tAverage Score: 16.75Total score (averaged over agents) this episode: 21.83149951202795\n",
      "Episode 287\tAverage Score: 16.84Total score (averaged over agents) this episode: 20.774999535642564\n",
      "Episode 288\tAverage Score: 16.92Total score (averaged over agents) this episode: 21.378999522142113\n",
      "Episode 289\tAverage Score: 16.99Total score (averaged over agents) this episode: 20.416999543644486\n",
      "Episode 290\tAverage Score: 17.07Total score (averaged over agents) this episode: 21.26749952463433\n",
      "Episode 291\tAverage Score: 17.16Total score (averaged over agents) this episode: 21.10499952826649\n",
      "Episode 292\tAverage Score: 17.25Total score (averaged over agents) this episode: 22.51349949678406\n",
      "Episode 293\tAverage Score: 17.34Total score (averaged over agents) this episode: 20.477499542292207\n",
      "Episode 294\tAverage Score: 17.40Total score (averaged over agents) this episode: 21.356499522645027\n",
      "Episode 295\tAverage Score: 17.47Total score (averaged over agents) this episode: 23.853999466821552\n",
      "Episode 296\tAverage Score: 17.55Total score (averaged over agents) this episode: 22.498999497108162\n",
      "Episode 297\tAverage Score: 17.63Total score (averaged over agents) this episode: 22.893999488279224\n",
      "Episode 298\tAverage Score: 17.72Total score (averaged over agents) this episode: 24.101999461278318\n",
      "Episode 299\tAverage Score: 17.82Total score (averaged over agents) this episode: 25.19899943675846\n",
      "Episode 300\tAverage Score: 17.93\n",
      "Total score (averaged over agents) this episode: 24.916499443072826\n",
      "Episode 301\tAverage Score: 18.04Total score (averaged over agents) this episode: 23.925999465212225\n",
      "Episode 302\tAverage Score: 18.14Total score (averaged over agents) this episode: 21.761999513581394\n",
      "Episode 303\tAverage Score: 18.20Total score (averaged over agents) this episode: 22.62599949426949\n",
      "Episode 304\tAverage Score: 18.28Total score (averaged over agents) this episode: 21.793499512877315\n",
      "Episode 305\tAverage Score: 18.35Total score (averaged over agents) this episode: 20.89449953297153\n",
      "Episode 306\tAverage Score: 18.40Total score (averaged over agents) this episode: 21.425499521102758\n",
      "Episode 307\tAverage Score: 18.46Total score (averaged over agents) this episode: 21.804499512631445\n",
      "Episode 308\tAverage Score: 18.51Total score (averaged over agents) this episode: 22.341999500617383\n",
      "Episode 309\tAverage Score: 18.59Total score (averaged over agents) this episode: 21.954499509278683\n",
      "Episode 310\tAverage Score: 18.64Total score (averaged over agents) this episode: 20.419999543577433\n",
      "Episode 311\tAverage Score: 18.69Total score (averaged over agents) this episode: 22.48199949748814\n",
      "Episode 312\tAverage Score: 18.76Total score (averaged over agents) this episode: 20.674499537888913\n",
      "Episode 313\tAverage Score: 18.79Total score (averaged over agents) this episode: 22.888499488402157\n",
      "Episode 314\tAverage Score: 18.86Total score (averaged over agents) this episode: 22.194499503914265\n",
      "Episode 315\tAverage Score: 18.93Total score (averaged over agents) this episode: 23.223499480914324\n",
      "Episode 316\tAverage Score: 19.01Total score (averaged over agents) this episode: 22.891499488335104\n",
      "Episode 317\tAverage Score: 19.08Total score (averaged over agents) this episode: 23.842499467078596\n",
      "Episode 318\tAverage Score: 19.16Total score (averaged over agents) this episode: 23.098999483697117\n",
      "Episode 319\tAverage Score: 19.24Total score (averaged over agents) this episode: 24.610999449901282\n",
      "Episode 320\tAverage Score: 19.31Total score (averaged over agents) this episode: 23.856499466765673\n",
      "Episode 321\tAverage Score: 19.37Total score (averaged over agents) this episode: 25.52249942952767\n",
      "Episode 322\tAverage Score: 19.47Total score (averaged over agents) this episode: 24.20149945905432\n",
      "Episode 323\tAverage Score: 19.55Total score (averaged over agents) this episode: 22.417999498918654\n",
      "Episode 324\tAverage Score: 19.63Total score (averaged over agents) this episode: 25.0444994402118\n",
      "Episode 325\tAverage Score: 19.70Total score (averaged over agents) this episode: 25.42549943169579\n",
      "Episode 326\tAverage Score: 19.80Total score (averaged over agents) this episode: 24.137499460484833\n",
      "Episode 327\tAverage Score: 19.90Total score (averaged over agents) this episode: 24.372499455232173\n",
      "Episode 328\tAverage Score: 19.98Total score (averaged over agents) this episode: 24.713999447599054\n",
      "Episode 329\tAverage Score: 20.06Total score (averaged over agents) this episode: 24.26099945772439\n",
      "Episode 330\tAverage Score: 20.14Total score (averaged over agents) this episode: 24.595499450247736\n",
      "Episode 331\tAverage Score: 20.26Total score (averaged over agents) this episode: 24.482999452762307\n",
      "Episode 332\tAverage Score: 20.33Total score (averaged over agents) this episode: 24.959999442100525\n",
      "Episode 333\tAverage Score: 20.42Total score (averaged over agents) this episode: 23.40349947689101\n",
      "Episode 334\tAverage Score: 20.50Total score (averaged over agents) this episode: 24.003499463479965\n",
      "Episode 335\tAverage Score: 20.58Total score (averaged over agents) this episode: 24.588499450404196\n",
      "Episode 336\tAverage Score: 20.65Total score (averaged over agents) this episode: 24.21599945873022\n",
      "Episode 337\tAverage Score: 20.73Total score (averaged over agents) this episode: 24.60849944995716\n",
      "Episode 338\tAverage Score: 20.82Total score (averaged over agents) this episode: 25.557999428734185\n",
      "Episode 339\tAverage Score: 20.92Total score (averaged over agents) this episode: 25.523999429494143\n",
      "Episode 340\tAverage Score: 21.00Total score (averaged over agents) this episode: 24.55499945115298\n",
      "Episode 341\tAverage Score: 21.07Total score (averaged over agents) this episode: 24.602999450080098\n",
      "Episode 342\tAverage Score: 21.14Total score (averaged over agents) this episode: 25.37099943291396\n",
      "Episode 343\tAverage Score: 21.23Total score (averaged over agents) this episode: 23.82249946752563\n",
      "Episode 344\tAverage Score: 21.30Total score (averaged over agents) this episode: 25.171499437373132\n",
      "Episode 345\tAverage Score: 21.39Total score (averaged over agents) this episode: 23.888499466050416\n",
      "Episode 346\tAverage Score: 21.44Total score (averaged over agents) this episode: 23.65649947123602\n",
      "Episode 347\tAverage Score: 21.49Total score (averaged over agents) this episode: 24.717999447509648\n",
      "Episode 348\tAverage Score: 21.54Total score (averaged over agents) this episode: 24.43749945377931\n",
      "Episode 349\tAverage Score: 21.62Total score (averaged over agents) this episode: 26.211999414116143\n",
      "Episode 350\tAverage Score: 21.69Total score (averaged over agents) this episode: 26.531499406974763\n",
      "Episode 351\tAverage Score: 21.77Total score (averaged over agents) this episode: 27.012499396223575\n",
      "Episode 352\tAverage Score: 21.86Total score (averaged over agents) this episode: 26.183499414753168\n",
      "Episode 353\tAverage Score: 21.94Total score (averaged over agents) this episode: 25.204499436635523\n",
      "Episode 354\tAverage Score: 22.00Total score (averaged over agents) this episode: 28.009999373927712\n",
      "Episode 355\tAverage Score: 22.08Total score (averaged over agents) this episode: 25.177999437227847\n",
      "Episode 356\tAverage Score: 22.12Total score (averaged over agents) this episode: 25.70049942554906\n",
      "Episode 357\tAverage Score: 22.19Total score (averaged over agents) this episode: 26.389999410137534\n",
      "Episode 358\tAverage Score: 22.25Total score (averaged over agents) this episode: 24.96649944195524\n",
      "Episode 359\tAverage Score: 22.30Total score (averaged over agents) this episode: 26.74299940224737\n",
      "Episode 360\tAverage Score: 22.36Total score (averaged over agents) this episode: 24.53449945161119\n",
      "Episode 361\tAverage Score: 22.42Total score (averaged over agents) this episode: 26.216999414004384\n",
      "Episode 362\tAverage Score: 22.50Total score (averaged over agents) this episode: 25.372999432869257\n",
      "Episode 363\tAverage Score: 22.58Total score (averaged over agents) this episode: 24.176499459613115\n",
      "Episode 364\tAverage Score: 22.61Total score (averaged over agents) this episode: 25.5769994283095\n",
      "Episode 365\tAverage Score: 22.67Total score (averaged over agents) this episode: 24.74499944690615\n",
      "Episode 366\tAverage Score: 22.74Total score (averaged over agents) this episode: 25.45849943095818\n",
      "Episode 367\tAverage Score: 22.83Total score (averaged over agents) this episode: 26.46099940855056\n",
      "Episode 368\tAverage Score: 22.93Total score (averaged over agents) this episode: 23.66749947099015\n",
      "Episode 369\tAverage Score: 22.97Total score (averaged over agents) this episode: 24.283999457210303\n",
      "Episode 370\tAverage Score: 23.02Total score (averaged over agents) this episode: 27.268999390490354\n",
      "Episode 371\tAverage Score: 23.10Total score (averaged over agents) this episode: 26.238999413512648\n",
      "Episode 372\tAverage Score: 23.19Total score (averaged over agents) this episode: 24.812999445386232\n",
      "Episode 373\tAverage Score: 23.27Total score (averaged over agents) this episode: 25.715499425213785\n",
      "Episode 374\tAverage Score: 23.35Total score (averaged over agents) this episode: 26.106499416474254\n",
      "Episode 375\tAverage Score: 23.41Total score (averaged over agents) this episode: 27.17649939255789\n",
      "Episode 376\tAverage Score: 23.51Total score (averaged over agents) this episode: 26.790499401185663\n",
      "Episode 377\tAverage Score: 23.60Total score (averaged over agents) this episode: 24.986999441497026\n",
      "Episode 378\tAverage Score: 23.68Total score (averaged over agents) this episode: 26.169999415054917\n",
      "Episode 379\tAverage Score: 23.77Total score (averaged over agents) this episode: 26.449499408807604\n",
      "Episode 380\tAverage Score: 23.86Total score (averaged over agents) this episode: 25.66149942642078\n",
      "Episode 381\tAverage Score: 23.93Total score (averaged over agents) this episode: 25.64599942676723\n",
      "Episode 382\tAverage Score: 23.99Total score (averaged over agents) this episode: 25.64599942676723\n",
      "Episode 383\tAverage Score: 24.07Total score (averaged over agents) this episode: 25.499999430030584\n",
      "Episode 384\tAverage Score: 24.13Total score (averaged over agents) this episode: 25.5914994279854\n",
      "Episode 385\tAverage Score: 24.18Total score (averaged over agents) this episode: 25.289499434735625\n",
      "Episode 386\tAverage Score: 24.23Total score (averaged over agents) this episode: 26.82199940048158\n",
      "Episode 387\tAverage Score: 24.28Total score (averaged over agents) this episode: 28.24349936870858\n",
      "Episode 388\tAverage Score: 24.36Total score (averaged over agents) this episode: 27.746499379817397\n",
      "Episode 389\tAverage Score: 24.42Total score (averaged over agents) this episode: 26.824999400414526\n",
      "Episode 390\tAverage Score: 24.48Total score (averaged over agents) this episode: 26.82699940036982\n",
      "Episode 391\tAverage Score: 24.54Total score (averaged over agents) this episode: 28.07149937255308\n",
      "Episode 392\tAverage Score: 24.61Total score (averaged over agents) this episode: 26.731499402504415\n",
      "Episode 393\tAverage Score: 24.65Total score (averaged over agents) this episode: 26.497499407734722\n",
      "Episode 394\tAverage Score: 24.71Total score (averaged over agents) this episode: 28.06049937279895\n",
      "Episode 395\tAverage Score: 24.78Total score (averaged over agents) this episode: 28.119499371480195\n",
      "Episode 396\tAverage Score: 24.82Total score (averaged over agents) this episode: 26.951499397587032\n",
      "Episode 397\tAverage Score: 24.87Total score (averaged over agents) this episode: 28.065999372676014\n",
      "Episode 398\tAverage Score: 24.92Total score (averaged over agents) this episode: 27.667499381583184\n",
      "Episode 399\tAverage Score: 24.95Total score (averaged over agents) this episode: 27.82299937810749\n",
      "Episode 400\tAverage Score: 24.98\n",
      "Total score (averaged over agents) this episode: 28.899999354034662\n",
      "Episode 401\tAverage Score: 25.02Total score (averaged over agents) this episode: 27.749999379739165\n",
      "Episode 402\tAverage Score: 25.06Total score (averaged over agents) this episode: 26.27349941274151\n",
      "Episode 403\tAverage Score: 25.10Total score (averaged over agents) this episode: 27.996999374218284\n",
      "Episode 404\tAverage Score: 25.16Total score (averaged over agents) this episode: 24.9179994430393\n",
      "Episode 405\tAverage Score: 25.19Total score (averaged over agents) this episode: 28.074499372486024\n",
      "Episode 406\tAverage Score: 25.26Total score (averaged over agents) this episode: 27.835499377828093\n",
      "Episode 407\tAverage Score: 25.32Total score (averaged over agents) this episode: 28.145999370887875\n",
      "Episode 408\tAverage Score: 25.39Total score (averaged over agents) this episode: 26.991999396681784\n",
      "Episode 409\tAverage Score: 25.43Total score (averaged over agents) this episode: 28.545999361947178\n",
      "Episode 410\tAverage Score: 25.50Total score (averaged over agents) this episode: 27.143499393295496\n",
      "Episode 411\tAverage Score: 25.57Total score (averaged over agents) this episode: 27.868499377090483\n",
      "Episode 412\tAverage Score: 25.62Total score (averaged over agents) this episode: 27.82799937799573\n",
      "Episode 413\tAverage Score: 25.69Total score (averaged over agents) this episode: 26.914499398414044\n",
      "Episode 414\tAverage Score: 25.73Total score (averaged over agents) this episode: 29.14199934862554\n",
      "Episode 415\tAverage Score: 25.80Total score (averaged over agents) this episode: 27.697999380901457\n",
      "Episode 416\tAverage Score: 25.85Total score (averaged over agents) this episode: 28.60299936067313\n",
      "Episode 417\tAverage Score: 25.90Total score (averaged over agents) this episode: 28.132499371189624\n",
      "Episode 418\tAverage Score: 25.95Total score (averaged over agents) this episode: 27.10499939415604\n",
      "Episode 419\tAverage Score: 25.99Total score (averaged over agents) this episode: 28.494999363087118\n",
      "Episode 420\tAverage Score: 26.03Total score (averaged over agents) this episode: 28.578499361220747\n",
      "Episode 421\tAverage Score: 26.07Total score (averaged over agents) this episode: 26.282499412540346\n",
      "Episode 422\tAverage Score: 26.08Total score (averaged over agents) this episode: 27.35349938860163\n",
      "Episode 423\tAverage Score: 26.11Total score (averaged over agents) this episode: 29.57199933901429\n",
      "Episode 424\tAverage Score: 26.18Total score (averaged over agents) this episode: 30.085499327536674\n",
      "Episode 425\tAverage Score: 26.23Total score (averaged over agents) this episode: 29.165499348100276\n",
      "Episode 426\tAverage Score: 26.27Total score (averaged over agents) this episode: 28.030499373469503\n",
      "Episode 427\tAverage Score: 26.31Total score (averaged over agents) this episode: 29.318499344680458\n",
      "Episode 428\tAverage Score: 26.36Total score (averaged over agents) this episode: 28.1609993705526\n",
      "Episode 429\tAverage Score: 26.39Total score (averaged over agents) this episode: 28.708999358303846\n",
      "Episode 430\tAverage Score: 26.44Total score (averaged over agents) this episode: 27.806499378476293\n",
      "Episode 431\tAverage Score: 26.47Total score (averaged over agents) this episode: 27.317499389406294\n",
      "Episode 432\tAverage Score: 26.50Total score (averaged over agents) this episode: 27.21999939158559\n",
      "Episode 433\tAverage Score: 26.52Total score (averaged over agents) this episode: 28.742999357543887\n",
      "Episode 434\tAverage Score: 26.58Total score (averaged over agents) this episode: 28.534499362204222\n",
      "Episode 435\tAverage Score: 26.62Total score (averaged over agents) this episode: 27.135499393474312\n",
      "Episode 436\tAverage Score: 26.65Total score (averaged over agents) this episode: 29.3089993448928\n",
      "Episode 437\tAverage Score: 26.70Total score (averaged over agents) this episode: 27.79199937880039\n",
      "Episode 438\tAverage Score: 26.73Total score (averaged over agents) this episode: 28.68049935894087\n",
      "Episode 439\tAverage Score: 26.76Total score (averaged over agents) this episode: 27.176999392546712\n",
      "Episode 440\tAverage Score: 26.78Total score (averaged over agents) this episode: 27.938999375514687\n",
      "Episode 441\tAverage Score: 26.81Total score (averaged over agents) this episode: 28.177499370183796\n",
      "Episode 442\tAverage Score: 26.85Total score (averaged over agents) this episode: 27.770999379269778\n",
      "Episode 443\tAverage Score: 26.87Total score (averaged over agents) this episode: 29.79099933411926\n",
      "Episode 444\tAverage Score: 26.93Total score (averaged over agents) this episode: 28.52649936238304\n",
      "Episode 445\tAverage Score: 26.96Total score (averaged over agents) this episode: 28.64199935980141\n",
      "Episode 446\tAverage Score: 27.01Total score (averaged over agents) this episode: 30.10299932714552\n",
      "Episode 447\tAverage Score: 27.08Total score (averaged over agents) this episode: 31.302499300334603\n",
      "Episode 448\tAverage Score: 27.14Total score (averaged over agents) this episode: 29.006999351643024\n",
      "Episode 449\tAverage Score: 27.19Total score (averaged over agents) this episode: 29.919999331235886\n",
      "Episode 450\tAverage Score: 27.22Total score (averaged over agents) this episode: 29.37549934340641\n",
      "Episode 451\tAverage Score: 27.25Total score (averaged over agents) this episode: 30.371999321132897\n",
      "Episode 452\tAverage Score: 27.29Total score (averaged over agents) this episode: 30.600499316025527\n",
      "Episode 453\tAverage Score: 27.33Total score (averaged over agents) this episode: 31.336499299574644\n",
      "Episode 454\tAverage Score: 27.39Total score (averaged over agents) this episode: 29.03199935108423\n",
      "Episode 455\tAverage Score: 27.40Total score (averaged over agents) this episode: 31.35049929926172\n",
      "Episode 456\tAverage Score: 27.46Total score (averaged over agents) this episode: 29.928499331045895\n",
      "Episode 457\tAverage Score: 27.51Total score (averaged over agents) this episode: 29.51499934028834\n",
      "Episode 458\tAverage Score: 27.54Total score (averaged over agents) this episode: 31.05149930594489\n",
      "Episode 459\tAverage Score: 27.60Total score (averaged over agents) this episode: 31.09499930497259\n",
      "Episode 460\tAverage Score: 27.64Total score (averaged over agents) this episode: 32.262999278865756\n",
      "Episode 461\tAverage Score: 27.72Total score (averaged over agents) this episode: 31.445499297138305\n",
      "Episode 462\tAverage Score: 27.77Total score (averaged over agents) this episode: 31.279999300837517\n",
      "Episode 463\tAverage Score: 27.83Total score (averaged over agents) this episode: 30.3139993224293\n",
      "Episode 464\tAverage Score: 27.89Total score (averaged over agents) this episode: 31.64249929273501\n",
      "Episode 465\tAverage Score: 27.95Total score (averaged over agents) this episode: 32.899999264627695\n",
      "Episode 466\tAverage Score: 28.03Total score (averaged over agents) this episode: 29.86599933244288\n",
      "Episode 467\tAverage Score: 28.08Total score (averaged over agents) this episode: 30.913999309018255\n",
      "Episode 468\tAverage Score: 28.12Total score (averaged over agents) this episode: 31.72599929086864\n",
      "Episode 469\tAverage Score: 28.20Total score (averaged over agents) this episode: 31.964499285537748\n",
      "Episode 470\tAverage Score: 28.28Total score (averaged over agents) this episode: 31.171999303251503\n",
      "Episode 471\tAverage Score: 28.32Total score (averaged over agents) this episode: 31.22599930204451\n",
      "Episode 472\tAverage Score: 28.37Total score (averaged over agents) this episode: 31.334499299619345\n",
      "Episode 473\tAverage Score: 28.43Total score (averaged over agents) this episode: 31.383999298512936\n",
      "Episode 474\tAverage Score: 28.49Total score (averaged over agents) this episode: 31.817499288823456\n",
      "Episode 475\tAverage Score: 28.55Total score (averaged over agents) this episode: 31.676999291963874\n",
      "Episode 476\tAverage Score: 28.59Total score (averaged over agents) this episode: 31.274999300949275\n",
      "Episode 477\tAverage Score: 28.64Total score (averaged over agents) this episode: 32.30799927785993\n",
      "Episode 478\tAverage Score: 28.71Total score (averaged over agents) this episode: 29.674999336712062\n",
      "Episode 479\tAverage Score: 28.75Total score (averaged over agents) this episode: 31.674499292019753\n",
      "Episode 480\tAverage Score: 28.80Total score (averaged over agents) this episode: 32.09349928265438\n",
      "Episode 481\tAverage Score: 28.86Total score (averaged over agents) this episode: 33.18749925820157\n",
      "Episode 482\tAverage Score: 28.94Total score (averaged over agents) this episode: 32.817499266471714\n",
      "Episode 483\tAverage Score: 29.01Total score (averaged over agents) this episode: 32.705999268963936\n",
      "Episode 484\tAverage Score: 29.08Total score (averaged over agents) this episode: 31.640999292768537\n",
      "Episode 485\tAverage Score: 29.14Total score (averaged over agents) this episode: 30.66149931466207\n",
      "Episode 486\tAverage Score: 29.20Total score (averaged over agents) this episode: 32.149499281402676\n",
      "Episode 487\tAverage Score: 29.25Total score (averaged over agents) this episode: 33.35149925453588\n",
      "Episode 488\tAverage Score: 29.30Total score (averaged over agents) this episode: 34.8314992214553\n",
      "Episode 489\tAverage Score: 29.37Total score (averaged over agents) this episode: 34.17199923619628\n",
      "Episode 490\tAverage Score: 29.44Total score (averaged over agents) this episode: 34.75799922309816\n",
      "Episode 491\tAverage Score: 29.52Total score (averaged over agents) this episode: 32.97199926301837\n",
      "Episode 492\tAverage Score: 29.57Total score (averaged over agents) this episode: 34.19899923559278\n",
      "Episode 493\tAverage Score: 29.65Total score (averaged over agents) this episode: 34.56949922731146\n",
      "Episode 494\tAverage Score: 29.73Total score (averaged over agents) this episode: 33.45999925211072\n",
      "Episode 495\tAverage Score: 29.78Total score (averaged over agents) this episode: 34.50349922878668\n",
      "Episode 496\tAverage Score: 29.85Total score (averaged over agents) this episode: 34.7319992236793\n",
      "Episode 497\tAverage Score: 29.92Total score (averaged over agents) this episode: 33.675999247282746\n",
      "Episode 498\tAverage Score: 29.98Total score (averaged over agents) this episode: 34.7049992242828\n",
      "Episode 499\tAverage Score: 30.05\n",
      "Environment solved in 399 episodes!\tAverage Score: 30.05\n"
     ]
    }
   ],
   "source": [
    "scores = ppo(agent , n_episodes = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Scores')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8dfdc727f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(scores)\n",
    "plt.xlabel(\"No. of episodes\")\n",
    "plt.ylabel(\"Scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
